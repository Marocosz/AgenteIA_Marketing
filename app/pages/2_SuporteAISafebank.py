# app/pages/2_aisup.py

import streamlit as st
from langchain_core.messages import AIMessage, HumanMessage
from dotenv import load_dotenv
from config import DOCS_PATH
from core_functions import load_llm, config_retriever, config_rag_chain

load_dotenv()

# --- CONFIGURA√á√ÉO INICIAL DA P√ÅGINA
st.set_page_config(page_title="Atendimento SafeBank ü§ñ", page_icon="ü§ñ")
st.title("Atendimento SafeBank")


# Carrega os recursos pesados usando o cache.
# O spinner mostra uma mensagem enquanto a fun√ß√£o √© executada pela PRIMEIRA VEZ.
with st.spinner("Carregando modelo de linguagem..."):
    llm = load_llm()
    
with st.spinner("Analisando e indexando documentos PDF... (isso pode levar um tempo na primeira vez)"):
    retriever = config_retriever(DOCS_PATH)

# Cria a RAG chain, tamb√©m com cache.
rag_chain = config_rag_chain(llm, retriever)

# Inicializa o hist√≥rico do chat na sess√£o se ele n√£o existir.
# Cria o "chat_history" dentro da sess√£o do streamlit e d√° a mensagem inicial
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [
        # AIMessage √© a classe para dizer que essa mensagem foi declarada pelo bot
        AIMessage(
            content="Ol√°! Sou o assistente virtual do SafeBank. Como posso te ajudar hoje?"),
    ]

# Mostra o hist√≥rico do chat na tela. 
for message in st.session_state.chat_history:
    # Define "AI" se a mensagem ta sendo instanciada pela classe AIMessage, se n√£o Role = "Human"
    role = "AI" if isinstance(message, AIMessage) else "Human"
    
    # Aqui o streamlit define os bal√µes de mensagem de acordo com a role
    with st.chat_message(role):
        # Aqui √© conte√∫do que vai aparecer
        st.write(message.content)

# Captura e processa a entrada do usu√°rio.
# Definimos a caixa de mensagem do streamlit com o placeholder "digite sua mensagem aqui..."
# e a mensagem do usu√°rio √© atribuido a essa variavel "user_input"
if user_input := st.chat_input("Digite sua mensagem aqui..."):
    # Cria o bal√£o de usu√°rio no estilo "Human" com oque o usu√°rio escreveu
    st.chat_message("Human").write(user_input)
    
    with st.chat_message("AI"):
        with st.spinner("Pensando..."):
            # Adiciona a nova pergunta ao hist√≥rico antes de invocar a chain
            st.session_state.chat_history.append(
                HumanMessage(content=user_input))

            # Executa a rag_chain 
            response = rag_chain.invoke({
                "input": user_input,  # A pergunta atual do usu√°rio
                "chat_history": st.session_state.chat_history  # O hist√≥rico de conversa
            })
            
            # A response retornada pela chain √© um dicion√°rio que pode conter v√°rias informa√ß√µes 
            # Aqui pegamos o valor da chave "answer" que √© texto final da resposta gerada pela IA
            answer = response["answer"]

            # Adiciona a resposta da IA ao hist√≥rico e √† tela
            st.session_state.chat_history.append(AIMessage(content=answer))
            st.write(answer)